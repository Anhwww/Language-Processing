{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I have to build a classification model to identify which language a text was written. I used logistic regression and naive bayes to train model."
      ],
      "metadata": {
        "id": "R7Tz61-PCU78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data [dataset.csv](https://drive.google.com/file/d/1US-ZpvKuXaNMN5TDjEh3_kOz-Z_OoSMM/view?usp=sharing)"
      ],
      "metadata": {
        "id": "b36km1L-82rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!rm -f dataset.csv\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id=\"1US-ZpvKuXaNMN5TDjEh3_kOz-Z_OoSMM\",\n",
        "                                    dest_path=\"./dataset.csv\",\n",
        "                                    )"
      ],
      "metadata": {
        "id": "aOebRSPy85Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head dataset.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4XZIzCVHQUK",
        "outputId": "ebba32a4-bd82-4839-b2ff-d541d757373a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text,language\r\n",
            "klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemärke  aastal viidi ta surnukeha mausoleumist ära ja kremeeriti zlíni linn kandis aastatel – nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel – nime gotvald,Estonian\r\n",
            "sebes joseph pereira thomas  på eng the jesuits and the sino-russian treaty of nerchinsk  the diary of thomas pereira bibliotheca instituti historici s i --   rome libris ,Swedish\r\n",
            "ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เริ่มตั้งแต่ถนนสนามไชยถึงแม่น้ำเจ้าพระยาที่ถนนตก กรุงเทพมหานคร เป็นถนนรุ่นแรกที่ใช้เทคนิคการสร้างแบบตะวันตก ปัจจุบันผ่านพื้นที่เขตพระนคร เขตป้อมปราบศัตรูพ่าย เขตสัมพันธวงศ์ เขตบางรัก เขตสาทร และเขตบางคอแหลม,Thai\r\n",
            "\"விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திரிகை-விசாகப்பட்டின ஆசிரியர் சம்பத்துடன் இணைந்து விரிவுபடுத்தினார்  ஆண்டுகள் தொடர்ந்து செயலராக இருந்து தமிழ்மன்றத்தை நடத்திச் சென்றார்  கோவை செம்மொழி மாநாட்டில் \"\"தமிழ்ச்சங்கங்களும் தமிழும்\"\" எனும் தலைப்பில் பிற மாநிலங்களில் தமிழ்வளர்ச்சி பற்றி கட்டுரை வாசித்தார்\",Tamil\r\n",
            "de spons behoort tot het geslacht haliclona en behoort tot de familie chalinidae de wetenschappelijke naam van de soort werd voor het eerst geldig gepubliceerd in  door kudelin,Dutch\r\n",
            "エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運転手に頼む際、本当のことを言ってしまうと彼女が恥ずかしい思いをすると察して「僕ウンコしたいんです」と言ってバスを降りた。エノは内心「私もしたいみたいじゃないの」と思うも、別れ際にエノの髪を「ふわふわのお菓子みたい」と言い、この台詞に憧れていたエノに強い衝撃を与えた。この話を聞いたリコは、以後彼のことを『ウンコ王子』または『ウンコ』というあだ名で呼ぶようになったが、エノは普通に「戸田くん」と呼んでいる。,Japanese\r\n",
            "tsutinalar i̇ngilizce tsuutina kanadada alberta bölgesinde calgaryde yaşarlar tek başına grup oluştururlar ve pasifik ve güney atabaskları ile antik yakınlıklar göstermiştir,Turkish\r\n",
            "müller mox figura centralis circulorum doctorum vindobonesium fiebat quibus intererant petrus altenberg albertus ehrenstein egon friedell anscharius kokoschka adolphus loos egon schiele et alii,Latin\r\n",
            "برقی بار electric charge تمام زیرجوہری ذرات کی ا یک بنیادی محفوظہ conserved خصوصیت ہے جو انکے برقناطیسی تفاعلات کا تعین کرتی ہے۔ اس بات یوں بھی کہ سکتے ہیں کہ برقی بار کا حامل ذرہ یا مادہ  ایک برقناطیسی میدان کی وجہ سے متاثر ہوتا ہے یا اسکے زیر اثر ہوتا ہے جبکہ خود اسی کی وجہ سے برقناطیسی میدان پیدا بھی ہوتا ہے۔ برقناطیسی میدان اور اس میں حرکت کرتے ہوئے ایک بار دار ذرے کے آپس میں تفاعل interaction سے ایک قسم کی قوت یا توانائی نمودار ہوتی ہے جس کو برقناطیسی قوت کہا جاتا ہے۔ اور یہ برقناطیسی قوت  دراصل اس کائنات میں پائی جانے والی چار بنیادی قوتوں میں سے ایک ہے۔,Urdu\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two columns in the data:\n",
        "\n",
        "- `Text` contains the content written in a certain language\n",
        "- `language` is the name of the language of the corresponding text.\n",
        "\n",
        "There are 22 labels in the dataset, and 1000 samples for each label."
      ],
      "metadata": {
        "id": "IxLrxaYfuxd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "def load_dataset(file_path):\n",
        "\n",
        "    texts = []\n",
        "    labels = []\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    try:\n",
        "        dataset = pd.read_csv('/content/drive/MyDrive/dataset.csv')\n",
        "        texts = dataset['Text'].tolist()\n",
        "        labels = dataset['language'].tolist()\n",
        "        unique_labels = list(set(labels))\n",
        "\n",
        "        print(\"Dataset loaded successfully.\")\n",
        "        print(\"Number of texts:\", len(texts))\n",
        "        print(\"Number of unique labels:\", len(unique_labels))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error loading dataset:\", e)\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "texts, labels = load_dataset('/content/drive/MyDrive/dataset.csv')"
      ],
      "metadata": {
        "id": "fRcz0v-UKSI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede36675-4c69-41a4-80d6-8211355edc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset loaded successfully.\n",
            "Number of texts: 22000\n",
            "Number of unique labels: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "texts, labels = load_dataset('/content/drive/MyDrive/dataset.csv')\n",
        "\n",
        "#I tried to print out 2 lists by mentioning it in the function load_dataset()\n",
        "#but there is too much output being generated, causing the notebook server to temporarily stop sending output"
      ],
      "metadata": {
        "id": "sbLQ1KxPMECW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2da391b-e2e0-405e-b4d5-6b6a35aac376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TGgUvVF1MR_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Feature extraction using character-level CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer='char')\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)\n",
        "# Define a function for feature extraction and model training\n",
        "def train_model(train_texts, train_labels, test_texts, test_labels, model_type='logistic_regression'):\n",
        "\n",
        "    # Initialize and train the model\n",
        "    if model_type == 'logistic_regression':\n",
        "        model = LogisticRegression(solver='lbfgs', max_iter=10000, C=0.1)\n",
        "    elif model_type == 'naive_bayes':\n",
        "        model = MultinomialNB()\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model type. Supported types: 'logistic_regression', 'naive_bayes'\")\n",
        "\n",
        "    model.fit(X_train, train_labels)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Train Logistic Regression model\n",
        "logistic_regression = train_model(train_texts, train_labels, test_texts, test_labels, model_type='logistic_regression')\n",
        "# Train Naive Bayes model\n",
        "naive_bayes = train_model(train_texts, train_labels, test_texts, test_labels, model_type='naive_bayes')\n"
      ],
      "metadata": {
        "id": "_cIwaxGWOrS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "y_test=test_labels\n",
        "# Define a function to evaluate the model and report classification results\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    # Get predicted labels for test samples\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Report classification results\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "evaluate_model(logistic_regression, X_test, y_test)\n",
        "\n",
        "# Evaluate the Naive Bayes model\n",
        "evaluate_model(naive_bayes, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "ESzpZ6dCUmJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fde760-bd34-4c71-c77e-01de9a109b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Arabic       1.00      1.00      1.00       202\n",
            "     Chinese       0.99      0.99      0.99       201\n",
            "       Dutch       0.94      0.93      0.94       230\n",
            "     English       0.80      0.90      0.85       194\n",
            "    Estonian       0.95      0.94      0.94       200\n",
            "      French       0.95      0.97      0.96       188\n",
            "       Hindi       1.00      0.99      0.99       208\n",
            "  Indonesian       0.99      0.97      0.98       213\n",
            "    Japanese       1.00      0.98      0.99       194\n",
            "      Korean       1.00      0.99      1.00       190\n",
            "       Latin       0.91      0.92      0.92       210\n",
            "     Persian       0.98      0.99      0.99       196\n",
            "   Portugese       0.95      0.92      0.93       194\n",
            "      Pushto       0.98      0.95      0.96       196\n",
            "    Romanian       1.00      0.97      0.98       197\n",
            "     Russian       0.99      1.00      0.99       213\n",
            "     Spanish       0.92      0.95      0.94       199\n",
            "     Swedish       0.97      1.00      0.99       179\n",
            "       Tamil       1.00      0.99      0.99       198\n",
            "        Thai       1.00      0.98      0.99       196\n",
            "     Turkish       0.99      0.98      0.99       199\n",
            "        Urdu       1.00      0.99      0.99       203\n",
            "\n",
            "    accuracy                           0.97      4400\n",
            "   macro avg       0.97      0.97      0.97      4400\n",
            "weighted avg       0.97      0.97      0.97      4400\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Arabic       1.00      1.00      1.00       202\n",
            "     Chinese       0.99      0.99      0.99       201\n",
            "       Dutch       0.94      0.91      0.93       230\n",
            "     English       0.71      0.97      0.82       194\n",
            "    Estonian       0.98      0.94      0.96       200\n",
            "      French       0.92      0.97      0.94       188\n",
            "       Hindi       1.00      0.99      0.99       208\n",
            "  Indonesian       1.00      0.95      0.97       213\n",
            "    Japanese       1.00      0.99      0.99       194\n",
            "      Korean       1.00      0.99      1.00       190\n",
            "       Latin       0.97      0.87      0.92       210\n",
            "     Persian       0.98      0.97      0.98       196\n",
            "   Portugese       0.96      0.91      0.93       194\n",
            "      Pushto       0.98      0.94      0.96       196\n",
            "    Romanian       0.99      0.97      0.98       197\n",
            "     Russian       0.99      1.00      0.99       213\n",
            "     Spanish       0.94      0.94      0.94       199\n",
            "     Swedish       0.98      0.99      0.99       179\n",
            "       Tamil       1.00      0.99      1.00       198\n",
            "        Thai       1.00      0.98      0.99       196\n",
            "     Turkish       1.00      0.98      0.99       199\n",
            "        Urdu       0.99      0.98      0.99       203\n",
            "\n",
            "    accuracy                           0.96      4400\n",
            "   macro avg       0.97      0.97      0.97      4400\n",
            "weighted avg       0.97      0.96      0.97      4400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(text):\n",
        "    \"\"\"\n",
        "    Return:\n",
        "        language: Language of the text\n",
        "    \"\"\"\n",
        "    language = None\n",
        "\n",
        "    # Transform the input text using the vectorizer\n",
        "    text_vectorized = vectorizer.transform([text])\n",
        "\n",
        "    # Use the trained model to predict the language\n",
        "    predicted_language = logistic_regression.predict(text_vectorized)\n",
        "\n",
        "    # Retrieve the predicted language (assuming it's a single prediction)\n",
        "    language = predicted_language[0]\n",
        "    return language"
      ],
      "metadata": {
        "id": "RBvJ9Tma6j-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classify(\"விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திரிகை-விசாகப்பட்டின ஆசிரியர் சம்பத்துடன் இணைந்து விரிவுபடுத்தினார்\")"
      ],
      "metadata": {
        "id": "tap-n0Ii6_jW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7df0ff5d-bfa5-4267-b1c1-c09fb6526c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tamil'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}